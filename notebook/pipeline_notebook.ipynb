{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import monotonically_increasing_id, col\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType, DoubleType, TimestampType\n",
    "sc = pyspark.SparkContext(appName='taxi-etl') # create SparkContext \n",
    "spark = SparkSession.builder.appName('taxi-etl') \\\n",
    "                    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "                    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess(spark_session, root_path):\n",
    "\n",
    "    # Create custom schema for the files\n",
    "    custom_schema = StructType([StructField('VendorID', LongType(), True),\n",
    "                                StructField('tpep_pickup_datetime', TimestampType(), True),\n",
    "                                StructField('tpep_dropoff_datetime', TimestampType(), True),\n",
    "                                StructField('passenger_count', DoubleType(), True),\n",
    "                                StructField('trip_distance', DoubleType(), True),\n",
    "                                StructField('RatecodeID', LongType(), True),\n",
    "                                StructField('store_and_fwd_flag', StringType(), True),\n",
    "                                StructField('PULocationID', LongType(), True),\n",
    "                                StructField('DOLocationID', LongType(), True),\n",
    "                                StructField('payment_type', LongType(), True),\n",
    "                                StructField('fare_amount', DoubleType(), True),\n",
    "                                StructField('extra', DoubleType(), True),\n",
    "                                StructField('mta_tax', DoubleType(), True),\n",
    "                                StructField('tip_amount', DoubleType(), True),\n",
    "                                StructField('tolls_amount', DoubleType(), True),\n",
    "                                StructField('improvement_surcharge', DoubleType(), True),\n",
    "                                StructField('total_amount', DoubleType(), True),\n",
    "                                StructField('congestion_surcharge', DoubleType(), True),\n",
    "                                StructField('airport_fee', DoubleType(), True),\n",
    "                                StructField('report_date', StringType(), True)\n",
    "    ])\n",
    "\n",
    "    # read the data from root_path\n",
    "    df = spark_session.read.schema(custom_schema).parquet(root_path)\n",
    "    \n",
    "    # clean the column names and perform type casting, add primary key trip_id\n",
    "    df = df.withColumnRenamed(\"VendorID\", \"vendor_id\") \\\n",
    "           .withColumnRenamed(\"PULocationID\", \"pick_up_location_id\") \\\n",
    "           .withColumnRenamed(\"DOLocationID\", \"drop_off_location_id\") \\\n",
    "           .withColumnRenamed(\"RatecodeID\", \"rate_code_id\") \\\n",
    "           .withColumnRenamed(\"payment_type\", \"payment_type_id\") \\\n",
    "           .withColumn(\"passenger_count\", col(\"passenger_count\").cast(LongType())) \\\n",
    "           .withColumn(\"trip_id\", monotonically_increasing_id())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vendor_id: long (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- rate_code_id: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- pick_up_location_id: long (nullable = true)\n",
      " |-- drop_off_location_id: long (nullable = true)\n",
      " |-- payment_type_id: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- report_date: string (nullable = true)\n",
      " |-- trip_id: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root_path = \"raw_data\"\n",
    "df = read_and_preprocess(spark, root_path)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+------------+-------------+-----------+-----------------+------------+-------------+--------------+------------+------------------+-------------+-----------+\n",
      "|tpep_pickup_datetime|tpep_dropoff_datetime|pick_up_year|pick_up_month|pick_up_day|pick_up_dayofweek|pick_up_hour|drop_off_year|drop_off_month|drop_off_day|drop_off_dayofweek|drop_off_hour|datetime_id|\n",
      "+--------------------+---------------------+------------+-------------+-----------+-----------------+------------+-------------+--------------+------------+------------------+-------------+-----------+\n",
      "| 2023-02-28 19:06:43|  2023-02-28 19:16:43|        2023|            2|         28|                3|          19|         2023|             2|          28|                 3|           19| 8589934592|\n",
      "| 2023-02-28 19:08:25|  2023-02-28 19:39:30|        2023|            2|         28|                3|          19|         2023|             2|          28|                 3|           19| 8589934593|\n",
      "| 2023-02-28 19:15:04|  2023-02-28 19:29:26|        2023|            2|         28|                3|          19|         2023|             2|          28|                 3|           19| 8589934594|\n",
      "| 2023-02-28 19:49:37|  2023-02-28 20:01:05|        2023|            2|         28|                3|          19|         2023|             2|          28|                 3|           20| 8589934595|\n",
      "| 2023-02-28 19:08:04|  2023-02-28 19:11:06|        2023|            2|         28|                3|          19|         2023|             2|          28|                 3|           19| 8589934596|\n",
      "+--------------------+---------------------+------------+-------------+-----------+-----------------+------------+-------------+--------------+------------+------------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import year, month, dayofmonth, dayofweek, hour\n",
    "\n",
    "# Construct datetime dimension table\n",
    "dim_datetime = df.select(\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\") \\\n",
    "                 .withColumn(\"pick_up_year\", year(\"tpep_pickup_datetime\")) \\\n",
    "                 .withColumn(\"pick_up_month\", month(\"tpep_pickup_datetime\")) \\\n",
    "                 .withColumn(\"pick_up_day\", dayofmonth(\"tpep_pickup_datetime\")) \\\n",
    "                 .withColumn(\"pick_up_dayofweek\", dayofweek(\"tpep_pickup_datetime\")) \\\n",
    "                 .withColumn(\"pick_up_hour\", hour(\"tpep_pickup_datetime\")) \\\n",
    "                 .withColumn(\"drop_off_year\", year(\"tpep_dropoff_datetime\")) \\\n",
    "                 .withColumn(\"drop_off_month\", month(\"tpep_dropoff_datetime\")) \\\n",
    "                 .withColumn(\"drop_off_day\", dayofmonth(\"tpep_dropoff_datetime\")) \\\n",
    "                 .withColumn(\"drop_off_dayofweek\", dayofweek(\"tpep_dropoff_datetime\")) \\\n",
    "                 .withColumn(\"drop_off_hour\", hour(\"tpep_dropoff_datetime\")) \\\n",
    "                 .withColumn(\"datetime_id\", monotonically_increasing_id())\n",
    "dim_datetime.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|rate_code_id|      rate_code_type|\n",
      "+------------+--------------------+\n",
      "|           1|       Standard rate|\n",
      "|           2|                 JFK|\n",
      "|           3|              Newark|\n",
      "|           4|Nassau or Westche...|\n",
      "|           5|     Negotiated fare|\n",
      "|           6|          Group ride|\n",
      "|          99|             Unknown|\n",
      "+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from pyspark.sql.functions import create_map, lit\n",
    "\n",
    "# Construct rate code dimension table according to mapping at https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "rate_code_mapping = {\n",
    "    1:\"Standard rate\",\n",
    "    2:\"JFK\",\n",
    "    3:\"Newark\",\n",
    "    4:\"Nassau or Westchester\",\n",
    "    5:\"Negotiated fare\",\n",
    "    6:\"Group ride\",\n",
    "    99:\"Unknown\"\n",
    "}\n",
    "\n",
    "mapping_func = create_map([lit(x) for x in chain(*rate_code_mapping.items())])\n",
    "dim_rate_code = df.select(\"rate_code_id\") \\\n",
    "                  .withColumn(\"rate_code_type\", mapping_func[col(\"rate_code_id\")]) \\\n",
    "                  .groupBy(\"rate_code_id\", \"rate_code_type\") \\\n",
    "                  .count() \\\n",
    "                  .orderBy(col(\"rate_code_id\").asc()) \\\n",
    "                  .drop(\"count\")     \n",
    "\n",
    "dim_rate_code.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|vendor_id|         vendor_info|\n",
      "+---------+--------------------+\n",
      "|        1|Creative Mobile T...|\n",
      "|        2|       VeriFone Inc.|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct vendor dimension table according to mapping at https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "vendor_mapping = {\n",
    "    1:\"Creative Mobile Technologies, LLC;\",\n",
    "    2:\"VeriFone Inc.\",\n",
    "    6:\"Unknown\"\n",
    "}\n",
    "\n",
    "mapping_func = create_map([lit(x) for x in chain(*vendor_mapping.items())])\n",
    "dim_vendor = df.select(\"vendor_id\") \\\n",
    "               .withColumn(\"vendor_info\", mapping_func[col(\"vendor_id\")]) \\\n",
    "               .groupBy(\"vendor_id\", \"vendor_info\") \\\n",
    "               .count() \\\n",
    "               .orderBy(col(\"vendor_id\").asc()) \\\n",
    "               .drop(\"count\")               \n",
    "\n",
    "dim_vendor.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+\n",
      "|payment_type_id|payment_type|\n",
      "+---------------+------------+\n",
      "|              1| Credit card|\n",
      "|              2|        Cash|\n",
      "|              3|   No charge|\n",
      "|              4|     Dispute|\n",
      "|              5|     Unknown|\n",
      "+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct payment type dimension table according to mapping at https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "payment_mapping = {\n",
    "    1:\"Credit card\",\n",
    "    2:\"Cash\",\n",
    "    3:\"No charge\",\n",
    "    4:\"Dispute\",\n",
    "    5:\"Unknown\",\n",
    "    6:\"Voided trip\",\n",
    "}\n",
    "\n",
    "mapping_func = create_map([lit(x) for x in chain(*payment_mapping.items())])\n",
    "dim_payment_type = df.select(\"payment_type_id\") \\\n",
    "                     .withColumn(\"payment_type\", mapping_func[col(\"payment_type_id\")]) \\\n",
    "                     .groupBy(\"payment_type_id\", \"payment_type\") \\\n",
    "                     .count() \\\n",
    "                     .orderBy(col(\"payment_type_id\").asc()) \\\n",
    "                     .drop(\"count\") \n",
    "\n",
    "dim_payment_type.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|passenger_count|passenger_count_id|\n",
      "+---------------+------------------+\n",
      "|              0|                 0|\n",
      "|              1|                 1|\n",
      "|              2|                 2|\n",
      "|              3|                 3|\n",
      "|              4|                 4|\n",
      "|              5|                 5|\n",
      "|              6|                 6|\n",
      "|              7|                 7|\n",
      "|              8|                 8|\n",
      "|              9|                 9|\n",
      "+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct passenger count dimension table \n",
    "dim_passenger_count = df.groupBy(col(\"passenger_count\").alias(\"passenger_count\")) \\\n",
    "                        .count() \\\n",
    "                        .orderBy(col(\"passenger_count\").asc()) \\\n",
    "                        .withColumn(\"passenger_count_id\", monotonically_increasing_id()) \\\n",
    "                        .drop(\"count\")\n",
    "\n",
    "dim_passenger_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+---------+------------+---------------+-------------+-----------+-------------------+--------------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------+\n",
      "|    trip_id|passenger_count_id|vendor_id|rate_code_id|payment_type_id|trip_distance|datetime_id|pick_up_location_id|drop_off_location_id|store_and_fwd_flag|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|report_date|\n",
      "+-----------+------------------+---------+------------+---------------+-------------+-----------+-------------------+--------------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------+\n",
      "|60132082359|                 1|        2|           1|              2|          0.0|60132082359|                193|                 264|                 N|        3.0|  0.0|    0.5|       0.0|         0.0|                  1.0|         4.5|                 0.0|        0.0|    2023-05|\n",
      "|85899367580|                 1|        2|           5|              1|          0.0|85899367580|                 48|                 264|                 N|       75.0|  0.0|    0.0|     15.06|         0.0|                  0.3|       90.36|                 0.0|        0.0|    2023-01|\n",
      "|85899368409|                 1|        2|           5|              1|          0.0|85899368409|                211|                 211|                 N|       55.0|  0.0|    0.0|     14.45|         0.0|                  0.3|       72.25|                 2.5|        0.0|    2023-01|\n",
      "|85899348426|                 1|        2|           1|              2|          1.7|85899348426|                125|                  68|                 N|        9.3|  1.0|    0.5|       0.0|         0.0|                  1.0|        14.3|                 2.5|        0.0|    2023-01|\n",
      "|85899350795|                 1|        2|           1|              1|        12.07|85899350795|                264|                 243|                 N|       46.4|  6.0|    0.5|       5.0|        6.55|                  1.0|        66.7|                 0.0|       1.25|    2023-01|\n",
      "|85899350271|                 2|        2|           1|              2|         13.4|85899350271|                246|                  14|                 N|       56.9|  1.0|    0.5|       0.0|         0.0|                  1.0|        61.9|                 2.5|        0.0|    2023-01|\n",
      "|85899346930|                 1|        1|           1|              1|          0.9|85899346930|                237|                 142|                 Y|        7.2|  3.5|    0.5|       2.4|         0.0|                  1.0|        14.6|                 2.5|        0.0|    2023-01|\n",
      "|85899346834|                 1|        2|           1|              1|         6.52|85899346834|                 88|                 140|                 N|       26.1|  1.0|    0.5|      7.78|         0.0|                  1.0|       38.88|                 2.5|        0.0|    2023-01|\n",
      "|85899347089|                 3|        2|           1|              1|         2.04|85899347089|                249|                 246|                 N|       15.6|  1.0|    0.5|       2.0|         0.0|                  1.0|        22.6|                 2.5|        0.0|    2023-01|\n",
      "|85899346027|                 1|        2|           1|              1|         0.71|85899346027|                125|                 231|                 N|        6.5|  1.0|    0.5|      1.72|         0.0|                  1.0|       13.22|                 2.5|        0.0|    2023-01|\n",
      "+-----------+------------------+---------+------------+---------------+-------------+-----------+-------------------+--------------------+------------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+-----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct fact table from all other tables\n",
    "fact_trips = df.withColumnRenamed(\"passenger_count\", \"passenger_count_id\") \\\n",
    "               .join(dim_datetime, on=['tpep_pickup_datetime', 'tpep_dropoff_datetime'], how=\"inner\") \\\n",
    "               .select(\"trip_id\", \"passenger_count_id\", \"vendor_id\", \"rate_code_id\", \"payment_type_id\", \"trip_distance\",\n",
    "                       \"datetime_id\", \"pick_up_location_id\", \"drop_off_location_id\", \"store_and_fwd_flag\",\n",
    "                       \"fare_amount\", \"extra\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\",\n",
    "                       \"total_amount\", \"congestion_surcharge\", \"airport_fee\", \"report_date\")\n",
    "\n",
    "fact_trips = fact_trips.coalesce(5)\n",
    "fact_trips.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_trips.write.parquet(\"transformed_data/fact_trips\")\n",
    "dim_passenger_count.write.parquet(\"transformed_data/dim_passenger_count\")\n",
    "dim_payment_type.write.parquet(\"transformed_data/dim_payment_type\")\n",
    "dim_vendor.write.parquet(\"transformed_data/dim_vendor\")\n",
    "dim_rate_code.write.parquet(\"transformed_data/dim_rate_code\")\n",
    "dim_datetime.write.parquet(\"transformed_data/dim_datetime\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
